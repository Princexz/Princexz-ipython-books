<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="IPython Cookbook, ">


    <!-- FAVICON -->
    <link rel="apple-touch-icon" sizes="57x57" href="/apple-touch-icon-57x57.png">
    <link rel="apple-touch-icon" sizes="114x114" href="/apple-touch-icon-114x114.png">
    <link rel="apple-touch-icon" sizes="72x72" href="/apple-touch-icon-72x72.png">
    <link rel="apple-touch-icon" sizes="144x144" href="/apple-touch-icon-144x144.png">
    <link rel="apple-touch-icon" sizes="60x60" href="/apple-touch-icon-60x60.png">
    <link rel="apple-touch-icon" sizes="120x120" href="/apple-touch-icon-120x120.png">
    <link rel="apple-touch-icon" sizes="76x76" href="/apple-touch-icon-76x76.png">
    <link rel="apple-touch-icon" sizes="152x152" href="/apple-touch-icon-152x152.png">
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon-180x180.png">
    <link rel="icon" type="image/png" href="/favicon-192x192.png" sizes="192x192">
    <link rel="icon" type="image/png" href="/favicon-160x160.png" sizes="160x160">
    <link rel="icon" type="image/png" href="/favicon-96x96.png" sizes="96x96">
    <link rel="icon" type="image/png" href="/favicon-16x16.png" sizes="16x16">
    <link rel="icon" type="image/png" href="/favicon-32x32.png" sizes="32x32">
    <meta name="msapplication-TileColor" content="#da532c">
    <meta name="msapplication-TileImage" content="/mstile-144x144.png">


        <link rel="alternate"  href="https://ipython-books.github.io/feeds/all.atom.xml" type="application/atom+xml" title="IPython Cookbook Full Atom Feed"/>

        <title>IPython Cookbook - 8.5. Using support vector machines for classification tasks</title>

    <link href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.2.0/css/font-awesome.min.css" rel="stylesheet">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/pure/0.3.0/pure-min.css">
    <!--[if lte IE 8]>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/0.5.0/pure-min.css">
    <![endif]-->
    <!--[if gt IE 8]><!-->
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/0.5.0/pure-min.css">
    <!--<![endif]-->
    <link rel="stylesheet" href="https://ipython-books.github.io/theme/css/styles.css">
    <link rel="stylesheet" href="https://ipython-books.github.io/theme/css/pygments.css">
    <!-- <link href='https://fonts.googleapis.com/css?family=Lato:300,400,700' rel='stylesheet' type='text/css'> -->
    <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,500" rel="stylesheet" type="text/css">
    <link href='https://fonts.googleapis.com/css?family=Ubuntu+Mono' rel='stylesheet' type='text/css'>
    

    <script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>
</head>

<body>


    <header id="header" class="pure-g">
        <div class="pure-u-1 pure-u-md-3-4">
             <div id="menu">
                 <div class="pure-menu pure-menu-open pure-menu-horizontal">
<ul>
        <li><a href="/">home</a></li>
        <li><a href="https://github.com/ipython-books/cookbook-2nd-code">Jupyter notebooks</a></li>
        <li><a href="https://github.com/ipython-books/minibook-2nd-code">minibook</a></li>
        <li><a href="https://cyrille.rossant.net">author</a></li>
</ul>                </div>
            </div>
        </div>

        <div class="pure-u-1 pure-u-md-1-4">
            <div id="social">
                <div class="pure-menu pure-menu-open pure-menu-horizontal">
<ul>
        <li><a href="https://twitter.com/cyrillerossant"><i class="fa fa-twitter"></i></a></li>
        <li><a href="https://github.com/ipython-books/cookbook-2nd"><i class="fa fa-github"></i></a></li>
</ul>                </div>
            </div>
        </div>
    </header>
       

    
    <div id="layout" class="pure-g">
        <section id="content" class="pure-u-1 pure-u-md-4-4">
            <div class="l-box">

    <header id="page-header">
        <h1>8.5. Using support vector machines for classification tasks</h1>
    </header>

    <section id="page">
        <p><a href="/"><img src="https://raw.githubusercontent.com/ipython-books/cookbook-2nd/master/cover-cookbook-2nd.png" align="left" alt="IPython Cookbook, Second Edition" height="130" style="margin-right: 20px; margin-bottom: 10px;" /></a> <em>This is one of the 100+ free recipes of the <a href="/">IPython Cookbook, Second Edition</a>, by <a href="http://cyrille.rossant.net">Cyrille Rossant</a>, a guide to numerical computing and data science in the Jupyter Notebook. The ebook and printed book are available for purchase at <a href="https://www.packtpub.com/big-data-and-business-intelligence/ipython-interactive-computing-and-visualization-cookbook-second-e">Packt Publishing</a>.</em></p>
<p>▶&nbsp;&nbsp;<em><a href="https://github.com/ipython-books/cookbook-2nd">Text on GitHub</a> with a <a href="https://creativecommons.org/licenses/by-nc-nd/3.0/us/legalcode">CC-BY-NC-ND license</a></em><br />
▶&nbsp;&nbsp;<em><a href="https://github.com/ipython-books/cookbook-2nd-code">Code on GitHub</a> with a <a href="https://opensource.org/licenses/MIT">MIT license</a></em></p>
<p>▶&nbsp;&nbsp;<a href="https://ipython-books.github.io/chapter-8-machine-learning/"><strong><em>Go to</em></strong> <em>Chapter 8 : Machine Learning</em></a><br />
▶&nbsp;&nbsp;<a href="https://github.com/ipython-books/cookbook-2nd-code/blob/master/chapter08_ml/05_svm.ipynb"><em><strong>Get</strong> the Jupyter notebook</em></a>  </p>
<p>In this recipe, we introduce <strong>support vector machines</strong>, or <strong>SVMs</strong>. These models can be used for classification and regression. Here, we illustrate how to use linear and nonlinear SVMs on a simple classification task. This recipe is inspired by an example in the scikit-learn documentation (see <a href="http://scikit-learn.org/stable/auto_examples/svm/plot_svm_nonlinear.html">http://scikit-learn.org/stable/auto_examples/svm/plot_svm_nonlinear.html</a>).</p>
<h2>How to do it...</h2>
<p><strong>1.&nbsp;</strong> Let's import the packages:</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">sklearn</span>
<span class="kn">import</span> <span class="nn">sklearn.datasets</span> <span class="kn">as</span> <span class="nn">ds</span>
<span class="kn">import</span> <span class="nn">sklearn.model_selection</span> <span class="kn">as</span> <span class="nn">ms</span>
<span class="kn">import</span> <span class="nn">sklearn.svm</span> <span class="kn">as</span> <span class="nn">svm</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
</pre></div>


<p><strong>2.&nbsp;</strong> We generate 2D points and assign a binary label according to a linear operation on the coordinates:</p>
<div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">200</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span>
</pre></div>


<p><strong>3.&nbsp;</strong> We now fit a linear <strong>Support Vector Classifier</strong> (SVC). This classifier tries to separate the two groups of points with a linear boundary (a line here, but more generally a hyperplane):</p>
<div class="highlight"><pre><span></span><span class="c1"># We train the classifier.</span>
<span class="n">est</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">LinearSVC</span><span class="p">()</span>
<span class="n">est</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>


<p><strong>4.&nbsp;</strong> We define a function that displays the boundaries and decision function of a trained classifier:</p>
<div class="highlight"><pre><span></span><span class="c1"># We generate a grid in the square [-3,3 ]^2.</span>
<span class="n">xx</span><span class="p">,</span> <span class="n">yy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">500</span><span class="p">),</span>
                     <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">500</span><span class="p">))</span>

<span class="c1"># This function takes a SVM estimator as input.</span>


<span class="k">def</span> <span class="nf">plot_decision_function</span><span class="p">(</span><span class="n">est</span><span class="p">,</span> <span class="n">title</span><span class="p">):</span>
    <span class="c1"># We evaluate the decision function on the grid.</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">est</span><span class="o">.</span><span class="n">decision_function</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">xx</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span>
                                    <span class="n">yy</span><span class="o">.</span><span class="n">ravel</span><span class="p">()])</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">Z</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">xx</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">cmap</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">Blues</span>

    <span class="c1"># We display the decision function on the grid.</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span>
              <span class="n">extent</span><span class="o">=</span><span class="p">(</span><span class="n">xx</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">xx</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span>
                      <span class="n">yy</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">yy</span><span class="o">.</span><span class="n">max</span><span class="p">()),</span>
              <span class="n">aspect</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span>
              <span class="n">origin</span><span class="o">=</span><span class="s1">&#39;lower&#39;</span><span class="p">,</span>
              <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">)</span>

    <span class="c1"># We display the boundaries.</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">contour</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="n">levels</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
               <span class="n">linewidths</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
               <span class="n">colors</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>

    <span class="c1"># We display the points with their true labels.</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
               <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">c</span><span class="o">=.</span><span class="mi">5</span> <span class="o">+</span> <span class="o">.</span><span class="mi">5</span> <span class="o">*</span> <span class="n">y</span><span class="p">,</span>
               <span class="n">edgecolors</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span>
               <span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span>
               <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">([</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_axis_off</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
</pre></div>


<p><strong>5.&nbsp;</strong> Let's take a look at the classification results with the linear SVC:</p>
<div class="highlight"><pre><span></span><span class="n">ax</span> <span class="o">=</span> <span class="n">plot_decision_function</span><span class="p">(</span>
    <span class="n">est</span><span class="p">,</span> <span class="s2">&quot;Linearly separable, linear SVC&quot;</span><span class="p">)</span>
</pre></div>


<p><img alt="&lt;matplotlib.figure.Figure at 0x93129e8&gt;" src="https://ipython-books.github.io/pages/chapter08_ml/05_svm_files/05_svm_12_0.png" /></p>
<p>The linear SVC tried to separate the points with a line and it did a pretty good job here.</p>
<p><strong>6.&nbsp;</strong> We now modify the labels with a <code>XOR</code> function. A point's label is 1 if the coordinates have different signs. This classification is not linearly separable. Therefore, a linear SVC fails completely:</p>
<div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logical_xor</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span>

<span class="c1"># We train the classifier.</span>
<span class="n">est</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">GridSearchCV</span><span class="p">(</span><span class="n">svm</span><span class="o">.</span><span class="n">LinearSVC</span><span class="p">(),</span>
                      <span class="p">{</span><span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="o">-</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mi">10</span><span class="p">)})</span>
<span class="n">est</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Score: {0:.1f}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
      <span class="n">ms</span><span class="o">.</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">est</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()))</span>

<span class="c1"># We plot the decision function.</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">plot_decision_function</span><span class="p">(</span>
    <span class="n">est</span><span class="p">,</span> <span class="s2">&quot;XOR, linear SVC&quot;</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span>Score: 0.5
</pre></div>


<p><img alt="&lt;matplotlib.figure.Figure at 0x46a2ef0&gt;" src="https://ipython-books.github.io/pages/chapter08_ml/05_svm_files/05_svm_15_1.png" /></p>
<p><strong>7.&nbsp;</strong> Fortunately, it is possible to use nonlinear SVCs by using <strong>nonlinear kernels</strong>. Kernels specify a nonlinear transformation of the points into a higher dimensional space. Transformed points in this space are assumed to be more linearly separable. By default, the <code>SVC</code> classifier in scikit-learn uses the <strong>Radial Basis Function (RBF)</strong> kernel:</p>
<div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logical_xor</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span>

<span class="n">est</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">GridSearchCV</span><span class="p">(</span>
    <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(),</span> <span class="p">{</span><span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="o">-</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
                <span class="s1">&#39;gamma&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="o">-</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mi">10</span><span class="p">)})</span>
<span class="n">est</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Score: {0:.3f}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
      <span class="n">ms</span><span class="o">.</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">est</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()))</span>

<span class="n">plot_decision_function</span><span class="p">(</span>
    <span class="n">est</span><span class="o">.</span><span class="n">best_estimator_</span><span class="p">,</span> <span class="s2">&quot;XOR, non-linear SVC&quot;</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span>Score: 0.955
</pre></div>


<p><img alt="&lt;matplotlib.figure.Figure at 0x5ad47f0&gt;" src="https://ipython-books.github.io/pages/chapter08_ml/05_svm_files/05_svm_17_1.png" /></p>
<p>This time, the nonlinear SVC successfully managed to classify these nonlinearly separable points.</p>
<h2>How it works...</h2>
<p>A two-class linear SVC tries to find a hyperplane (defined as a linear equation) that best separates the two sets of points (grouped according to their labels). There is also the constraint that this separating hyperplane needs to be as far as possible from the points. This method works best when such a hyperplane exists. Otherwise, this method can fail completely, as we saw in the <code>XOR</code> example. <code>XOR</code> is known as being a nonlinearly separable operation.</p>
<p>The SVM classes in scikit-learn have a <code>C</code> hyperparameter. This hyperparameter trades off misclassification of training examples against simplicity of the decision surface. A low C value makes the decision surface smooth, while a high C value aims at classifying all training examples correctly. This is another example where a hyperparameter quantifies the bias-variance trade-off. This hyperparameter can be chosen with cross-validation and grid search.</p>
<p>The linear SVC can also be extended to multi-class problems. The multi-class SVC is directly implemented in scikit-learn.</p>
<p>The nonlinear SVC works by considering a nonlinear transformation <span class="math">\(\phi(x)\)</span> from the original space into a higher dimensional space. This nonlinear transformation can increase the linear separability of the classes. In practice, all dot products are replaced by the <span class="math">\(k(x,x') = \phi(x) \cdot \phi(x')\)</span> kernel.</p>
<p><img alt="Non-linear SVC" src="https://ipython-books.github.io/pages/chapter08_ml/05_svm_files/kernel.png" /></p>
<p>There are several widely-used nonlinear kernels. By default, SVC uses Gaussian radial basis functions:</p>
<div class="math">$$k(\mathbf{x}, \mathbf{x'}) = \exp\left(-\gamma||\mathbf{x}-\mathbf{x'}||^2\right)$$</div>
<p>Here, <span class="math">\(\gamma\)</span> is a hyperparameter of the model that can be chosen with grid search and cross-validation.</p>
<p>The <span class="math">\(\phi\)</span> function does not need to be computed explicitly. This is the <strong>kernel trick</strong>; it suffices to know the kernel <span class="math">\(k(x,x')\)</span>. The existence of a function <span class="math">\(\phi\)</span> corresponding to a given kernel <span class="math">\(k(x, x')\)</span> is guaranteed by a mathematical theorem in functional analysis (Mercer's theorem).</p>
<h2>There's more...</h2>
<p>Here are a few references about support vector machines:</p>
<ul>
<li>Exclusive OR on Wikipedia, available at <a href="https://en.wikipedia.org/wiki/Exclusive_or">https://en.wikipedia.org/wiki/Exclusive_or</a></li>
<li>Support vector machines on Wikipedia, available at <a href="https://en.wikipedia.org/wiki/Support_vector_machine">https://en.wikipedia.org/wiki/Support_vector_machine</a></li>
<li>SVMs in scikit-learn's documentation, available at <a href="http://scikit-learn.org/stable/modules/svm.html">http://scikit-learn.org/stable/modules/svm.html</a></li>
<li>Kernel trick on Wikipedia, available at <a href="https://en.wikipedia.org/wiki/Kernel_method">https://en.wikipedia.org/wiki/Kernel_method</a></li>
<li>Notes about the kernel trick available at <a href="http://www.eric-kim.net/eric-kim-net/posts/1/kernel_trick.html">http://www.eric-kim.net/eric-kim-net/posts/1/kernel_trick.html</a></li>
</ul>
<h2>See also</h2>
<ul>
<li>Predicting who will survive on the Titanic with logistic regression</li>
<li>Learning to recognize handwritten digits with a K-nearest neighbors classifier</li>
</ul>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
    </section>

            </div>
        </section>

        <footer id="footer" class="pure-u-1 pure-u-md-4-4">
            <div class="l-box">
                <div>
                    <p>&copy; <a href="https://cyrille.rossant.net">Cyrille Rossant</a> &ndash;
                        Built with <a href="https://github.com/PurePelicanTheme/pure-single">Pure Theme</a>
                        for <a href="https://blog.getpelican.com/">Pelican</a>
                    </p>
                </div>
            </div>
        </footer>
        
    </div>
    
<!-- Start of StatCounter Code for Default Guide -->
<script type="text/javascript">
var sc_project=9752080; 
var sc_invisible=1; 
var sc_security="c177b501"; 
var scJsHost = (("https:" == document.location.protocol) ?
"https://secure." : "http://www.");
</script>
<script type="text/javascript"
src="https://www.statcounter.com/counter/counter.js"
async></script>
<noscript><div class="statcounter"><a title="Web Analytics"
href="https://statcounter.com/" target="_blank"><img
class="statcounter"
src="//c.statcounter.com/9752080/0/c177b501/1/" alt="Web
Analytics"></a></div></noscript>
<!-- End of StatCounter Code for Default Guide -->
</body>
</html>