<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="IPython Cookbook, ">


    <!-- FAVICON -->
    <link rel="apple-touch-icon" sizes="57x57" href="/apple-touch-icon-57x57.png">
    <link rel="apple-touch-icon" sizes="114x114" href="/apple-touch-icon-114x114.png">
    <link rel="apple-touch-icon" sizes="72x72" href="/apple-touch-icon-72x72.png">
    <link rel="apple-touch-icon" sizes="144x144" href="/apple-touch-icon-144x144.png">
    <link rel="apple-touch-icon" sizes="60x60" href="/apple-touch-icon-60x60.png">
    <link rel="apple-touch-icon" sizes="120x120" href="/apple-touch-icon-120x120.png">
    <link rel="apple-touch-icon" sizes="76x76" href="/apple-touch-icon-76x76.png">
    <link rel="apple-touch-icon" sizes="152x152" href="/apple-touch-icon-152x152.png">
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon-180x180.png">
    <link rel="icon" type="image/png" href="/favicon-192x192.png" sizes="192x192">
    <link rel="icon" type="image/png" href="/favicon-160x160.png" sizes="160x160">
    <link rel="icon" type="image/png" href="/favicon-96x96.png" sizes="96x96">
    <link rel="icon" type="image/png" href="/favicon-16x16.png" sizes="16x16">
    <link rel="icon" type="image/png" href="/favicon-32x32.png" sizes="32x32">
    <meta name="msapplication-TileColor" content="#da532c">
    <meta name="msapplication-TileImage" content="/mstile-144x144.png">


        <link rel="alternate"  href="https://ipython-books.github.io/feeds/all.atom.xml" type="application/atom+xml" title="IPython Cookbook Full Atom Feed"/>

        <title>IPython Cookbook - 7.7. Fitting a Bayesian model by sampling from a posterior distribution with a Markov Chain Monte Carlo method</title>

    <link href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.2.0/css/font-awesome.min.css" rel="stylesheet">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/pure/0.3.0/pure-min.css">
    <!--[if lte IE 8]>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/0.5.0/pure-min.css">
    <![endif]-->
    <!--[if gt IE 8]><!-->
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/0.5.0/pure-min.css">
    <!--<![endif]-->
    <link rel="stylesheet" href="https://ipython-books.github.io/theme/css/styles.css">
    <link rel="stylesheet" href="https://ipython-books.github.io/theme/css/pygments.css">
    <!-- <link href='https://fonts.googleapis.com/css?family=Lato:300,400,700' rel='stylesheet' type='text/css'> -->
    <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,500" rel="stylesheet" type="text/css">
    <link href='https://fonts.googleapis.com/css?family=Ubuntu+Mono' rel='stylesheet' type='text/css'>
    

    <script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>
</head>

<body>


    <header id="header" class="pure-g">
        <div class="pure-u-1 pure-u-md-3-4">
             <div id="menu">
                 <div class="pure-menu pure-menu-open pure-menu-horizontal">
<ul>
        <li><a href="/">home</a></li>
        <li><a href="https://github.com/ipython-books/cookbook-2nd-code">Jupyter notebooks</a></li>
        <li><a href="https://github.com/ipython-books/minibook-2nd-code">minibook</a></li>
        <li><a href="https://cyrille.rossant.net">author</a></li>
</ul>                </div>
            </div>
        </div>

        <div class="pure-u-1 pure-u-md-1-4">
            <div id="social">
                <div class="pure-menu pure-menu-open pure-menu-horizontal">
<ul>
        <li><a href="https://twitter.com/cyrillerossant"><i class="fa fa-twitter"></i></a></li>
        <li><a href="https://github.com/ipython-books/cookbook-2nd"><i class="fa fa-github"></i></a></li>
</ul>                </div>
            </div>
        </div>
    </header>
       

    
    <div id="layout" class="pure-g">
        <section id="content" class="pure-u-1 pure-u-md-4-4">
            <div class="l-box">

    <header id="page-header">
        <h1>7.7. Fitting a Bayesian model by sampling from a posterior distribution with a Markov Chain Monte Carlo method</h1>
    </header>

    <section id="page">
        <p><a href="/"><img src="https://raw.githubusercontent.com/ipython-books/cookbook-2nd/master/cover-cookbook-2nd.png" align="left" alt="IPython Cookbook, Second Edition" height="130" style="margin-right: 20px; margin-bottom: 10px;" /></a> <em>This is one of the 100+ free recipes of the <a href="/">IPython Cookbook, Second Edition</a>, by <a href="http://cyrille.rossant.net">Cyrille Rossant</a>, a guide to numerical computing and data science in the Jupyter Notebook. The ebook and printed book are available for purchase at <a href="https://www.packtpub.com/big-data-and-business-intelligence/ipython-interactive-computing-and-visualization-cookbook-second-e">Packt Publishing</a>.</em></p>
<p>▶&nbsp;&nbsp;<em><a href="https://github.com/ipython-books/cookbook-2nd">Text on GitHub</a> with a <a href="https://creativecommons.org/licenses/by-nc-nd/3.0/us/legalcode">CC-BY-NC-ND license</a></em><br />
▶&nbsp;&nbsp;<em><a href="https://github.com/ipython-books/cookbook-2nd-code">Code on GitHub</a> with a <a href="https://opensource.org/licenses/MIT">MIT license</a></em></p>
<p>▶&nbsp;&nbsp;<a href="https://ipython-books.github.io/chapter-7-statistical-data-analysis/"><strong><em>Go to</em></strong> <em>Chapter 7 : Statistical Data Analysis</em></a><br />
▶&nbsp;&nbsp;<a href="https://github.com/ipython-books/cookbook-2nd-code/blob/master/chapter07_stats/07_pymc.ipynb"><em><strong>Get</strong> the Jupyter notebook</em></a>  </p>
<p>In this recipe, we illustrate a very common and useful method for characterizing a posterior distribution in a Bayesian model. Imagine that you have some data and you want to obtain information about the underlying random phenomenon. In a frequentist approach, you could try to fit a probability distribution within a given family of distributions, using a parametric method such as the maximum likelihood method. The optimization procedure would yield parameters that maximize the probability of observing the data if given the null hypothesis.</p>
<p>In a Bayesian approach, you consider the parameters themselves as random variables. Their prior distributions reflect your initial knowledge about these parameters. After the observations, your knowledge is updated, and this is reflected in the posterior distributions of the parameters.</p>
<p>A typical goal for Bayesian inference is to characterize the posterior distributions. Bayes' theorem gives an analytical way to do this, but it is often impractical in real-world problems due to the complexity of the models and the number of dimensions. A <strong>Markov chain Monte Carlo method</strong>, such as the <strong>Metropolis-Hastings algorithm</strong>, gives a numerical method to approximate a posterior distribution.</p>
<p>Here, we introduce the <strong>PyMC3</strong> package, which gives an effective and natural interface for fitting a probabilistic model to data in a Bayesian framework. We will look at the annual frequency of storms in the northern Atlantic Ocean since the 1850s using data from NOAA, the US' National Oceanic and Atmospheric Administration. This example is largely inspired by the tutorial available in the official PyMC3 documentation at <a href="http://docs.pymc.io/notebooks/getting_started.html#Case-study-2:-Coal-mining-disasters.">http://docs.pymc.io/notebooks/getting_started.html#Case-study-2:-Coal-mining-disasters.</a></p>
<h2>Getting ready</h2>
<p>You need PyMC3, available at <a href="http://docs.pymc.io.">http://docs.pymc.io.</a> You can install it with <code>conda install -c conda-forge pymc3</code>.</p>
<h2>How to do it...</h2>
<p><strong>1.&nbsp;</strong> Let's import the standard packages and PyMC3:</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">pymc3</span> <span class="kn">as</span> <span class="nn">pm</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
</pre></div>


<p><strong>2.&nbsp;</strong> Let's import the data with pandas:</p>
<div class="highlight"><pre><span></span><span class="c1"># www.ncdc.noaa.gov/ibtracs/index.php?name=wmo-data</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;https://github.com/ipython-books/&#39;</span>
                 <span class="s1">&#39;cookbook-2nd-data/blob/master/&#39;</span>
                 <span class="s1">&#39;Allstorms.ibtracs_wmo.v03r05.csv?&#39;</span>
                 <span class="s1">&#39;raw=true&#39;</span><span class="p">,</span>
                 <span class="n">delim_whitespace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</pre></div>


<p><strong>3.&nbsp;</strong> With pandas, it only takes a single line of code to get the annual number of storms in the North Atlantic Ocean. We first select the storms in that basin (<code>NA</code>), then we group the rows by year (<code>Season</code>), and finally we take the number of unique storms (<code>Serial_Num</code>), as each storm can span several days (the <code>nunique()</code> method):</p>
<div class="highlight"><pre><span></span><span class="n">cnt</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Basin&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39; NA&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span>
    <span class="s1">&#39;Season&#39;</span><span class="p">)[</span><span class="s1">&#39;Serial_Num&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">nunique</span><span class="p">()</span>
<span class="c1"># The years from 1851 to 2012.</span>
<span class="n">years</span> <span class="o">=</span> <span class="n">cnt</span><span class="o">.</span><span class="n">index</span>
<span class="n">y0</span><span class="p">,</span> <span class="n">y1</span> <span class="o">=</span> <span class="n">years</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">years</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">arr</span> <span class="o">=</span> <span class="n">cnt</span><span class="o">.</span><span class="n">values</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="c1"># Plot the annual number of storms.</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">years</span><span class="p">,</span> <span class="n">arr</span><span class="p">,</span> <span class="s1">&#39;-o&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">y0</span><span class="p">,</span> <span class="n">y1</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Year&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Number of storms&quot;</span><span class="p">)</span>
</pre></div>


<p><img alt="&lt;matplotlib.figure.Figure at 0xcef94e0&gt;" src="https://ipython-books.github.io/pages/chapter07_stats/07_pymc_files/07_pymc_14_0.png" /></p>
<p><strong>4.&nbsp;</strong> Now, we define our probabilistic model. We assume that storms arise following a time-dependent <strong>Poisson process</strong> with a deterministic rate. We assume that this rate is a piecewise-constant function that takes a first value <code>early_mean</code> before a switch point <code>switchpoint</code>, and a second value <code>late_mean</code> after that point. These three unknown parameters are treated as random variables (we will describe them more in the <em>How it works...</em> section). In the model, the annual number of storms per year follows a Poisson distribution (this is a property of Poisson processes).</p>
<blockquote>
<p>A Poisson process (https://en.wikipedia.org/wiki/Poisson_process) is a particular <strong>point process</strong>, that is, a stochastic process describing the random occurrence of instantaneous events. The Poisson process is fully random: the events occur independently at a given rate. See also <em>Chapter 13, Stochastic Dynamical Systems</em>.</p>
</blockquote>
<div class="highlight"><pre><span></span><span class="c1"># We define our model.</span>
<span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">model</span><span class="p">:</span>
    <span class="c1"># We define our three variables.</span>
    <span class="n">switchpoint</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">DiscreteUniform</span><span class="p">(</span>
        <span class="s1">&#39;switchpoint&#39;</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="n">y0</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="n">y1</span><span class="p">)</span>
    <span class="n">early_rate</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Exponential</span><span class="p">(</span><span class="s1">&#39;early_rate&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">late_rate</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Exponential</span><span class="p">(</span><span class="s1">&#39;late_rate&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="c1"># The rate of the Poisson process is a piecewise</span>
    <span class="c1"># constant function.</span>
    <span class="n">rate</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">switch</span><span class="p">(</span><span class="n">switchpoint</span> <span class="o">&gt;=</span> <span class="n">years</span><span class="p">,</span>
                          <span class="n">early_rate</span><span class="p">,</span> <span class="n">late_rate</span><span class="p">)</span>
    <span class="c1"># The annual number of storms per year follows</span>
    <span class="c1"># a Poisson distribution.</span>
    <span class="n">storms</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Poisson</span><span class="p">(</span><span class="s1">&#39;storms&#39;</span><span class="p">,</span> <span class="n">rate</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">arr</span><span class="p">)</span>
</pre></div>


<p><strong>5.&nbsp;</strong> Now, we sample from the posterior distribution given the observed data. The <code>sample(10000)</code> method launches the fitting iterative procedure with 10000 iterations, which may take a few seconds:</p>
<div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">model</span><span class="p">:</span>
    <span class="n">trace</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">10000</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span>Assigned Metropolis to switchpoint
Assigned NUTS to early_rate_log__
Assigned NUTS to late_rate_log__
100%|██████████| 10500/10500 [00:05&lt;00:00, 1757.23it/s]
</pre></div>


<p><strong>6.&nbsp;</strong> Once the sampling has finished, we can plot the distribution and paths of the Markov chains:</p>
<div class="highlight"><pre><span></span><span class="n">pm</span><span class="o">.</span><span class="n">traceplot</span><span class="p">(</span><span class="n">trace</span><span class="p">)</span>
</pre></div>


<p><img alt="&lt;matplotlib.figure.Figure at 0x7f6adb76ec88&gt;" src="https://ipython-books.github.io/pages/chapter07_stats/07_pymc_files/07_pymc_21_0.png" /></p>
<p>Each row represents a variable. The left plot is a histogram of the corresponding Markov chain, which gives the posterior distribution of the variable. The right plot is an arbitrarily-chosen path of a Markov chain, showing the evolution of the variable during the fitting procedure.</p>
<p><strong>7.&nbsp;</strong> Taking the sample mean of these distributions, we get posterior estimates for the three unknown parameters, including the year where the frequency of storms suddenly increased:</p>
<div class="highlight"><pre><span></span><span class="n">s</span> <span class="o">=</span> <span class="n">trace</span><span class="p">[</span><span class="s1">&#39;switchpoint&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">em</span> <span class="o">=</span> <span class="n">trace</span><span class="p">[</span><span class="s1">&#39;early_rate&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">lm</span> <span class="o">=</span> <span class="n">trace</span><span class="p">[</span><span class="s1">&#39;late_rate&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">s</span><span class="p">,</span> <span class="n">em</span><span class="p">,</span> <span class="n">lm</span>
</pre></div>


<div class="highlight"><pre><span></span>(1930.171, 7.316, 14.085)
</pre></div>


<p><strong>8.&nbsp;</strong> Finally, we can plot the estimated rate on top of the observations:</p>
<div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">years</span><span class="p">,</span> <span class="n">arr</span><span class="p">,</span> <span class="s1">&#39;-o&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">y0</span><span class="p">,</span> <span class="n">s</span><span class="p">],</span> <span class="p">[</span><span class="n">em</span><span class="p">,</span> <span class="n">em</span><span class="p">],</span> <span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">s</span><span class="p">,</span> <span class="n">y1</span><span class="p">],</span> <span class="p">[</span><span class="n">lm</span><span class="p">,</span> <span class="n">lm</span><span class="p">],</span> <span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">y0</span><span class="p">,</span> <span class="n">y1</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Year&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Number of storms&quot;</span><span class="p">)</span>
</pre></div>


<p><img alt="&lt;matplotlib.figure.Figure at 0xccfe358&gt;" src="https://ipython-books.github.io/pages/chapter07_stats/07_pymc_files/07_pymc_26_0.png" /></p>
<h2>How it works...</h2>
<p>The general idea is to define a Bayesian probabilistic model and to fit it to the data. This model may be the starting point of an estimation or decision task. The model is essentially described by stochastic or deterministic variables linked together within a <strong>direct acyclic graph (DAG)</strong>. A is linked to B if B is entirely or partially determined by A. The following figure shows the graph of the model used in this recipe:</p>
<p><img alt="Dependency graph of the variables" src="https://ipython-books.github.io/pages/chapter07_stats/07_pymc_files/graph.png" /></p>
<p>Stochastic variables follow distributions that can be parameterized by fixed numbers or other variables in the model. Parameters may be random variables themselves, reflecting knowledge prior to the observations. This is the core of Bayesian modeling.</p>
<p>The goal of the analysis is to include the observations into the model in order to update our knowledge as more and more data is available. Although Bayes' theorem gives us an exact way to compute those posterior distributions, it is rarely practical in real-world problems. This is notably due to the complexity of the models. Alternatively, numerical methods have been developed in order to tackle this problem.</p>
<p>The <strong>Markov chain Monte Carlo (MCMC) method</strong> used here allows us to sample from a complex distribution by simulating a Markov chain that has the desired distribution as its equilibrium distribution. The <strong>Metropolis-Hastings algorithm</strong> is a particular application of this method to our current example.</p>
<h2>There's more...</h2>
<p>Here are a few references:</p>
<ul>
<li>A free e-book on the subject, by Cameron Davidson-Pilon, entirely written in the Jupyter Notebook, available at <a href="http://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/">http://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/</a></li>
<li>The Markov chain Monte Carlo method introduced at <a href="https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo">https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo</a></li>
<li>The Metropolis-Hastings algorithm introduced at <a href="https://en.wikipedia.org/wiki/Metropolis-Hastings_algorithm">https://en.wikipedia.org/wiki/Metropolis-Hastings_algorithm</a></li>
</ul>
<h2>See also</h2>
<ul>
<li>Getting started with Bayesian methods</li>
</ul>
    </section>

            </div>
        </section>

        <footer id="footer" class="pure-u-1 pure-u-md-4-4">
            <div class="l-box">
                <div>
                    <p>&copy; <a href="https://cyrille.rossant.net">Cyrille Rossant</a> &ndash;
                        Built with <a href="https://github.com/PurePelicanTheme/pure-single">Pure Theme</a>
                        for <a href="https://blog.getpelican.com/">Pelican</a>
                    </p>
                </div>
            </div>
        </footer>
        
    </div>
    
<!-- Start of StatCounter Code for Default Guide -->
<script type="text/javascript">
var sc_project=9752080; 
var sc_invisible=1; 
var sc_security="c177b501"; 
var scJsHost = (("https:" == document.location.protocol) ?
"https://secure." : "http://www.");
</script>
<script type="text/javascript"
src="https://www.statcounter.com/counter/counter.js"
async></script>
<noscript><div class="statcounter"><a title="Web Analytics"
href="https://statcounter.com/" target="_blank"><img
class="statcounter"
src="//c.statcounter.com/9752080/0/c177b501/1/" alt="Web
Analytics"></a></div></noscript>
<!-- End of StatCounter Code for Default Guide -->
</body>
</html>